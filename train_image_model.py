import getopt
import sys
import numpy as np
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.applications.inception_v3 import preprocess_input
from tensorflow.keras.applications.mobilenet import preprocess_input
from tensorflow.keras.applications import MobileNet
from tensorflow.keras.applications import InceptionV3
import tensorflow.keras
import json
import file_utils


def random_crop(img, random_crop_size):
    # Note: image_data_format is 'channel_last'
    assert img.shape[2] == 3
    height, width = img.shape[0], img.shape[1]
    dy, dx = random_crop_size
    x = np.random.randint(0, width - dx + 1)
    y = np.random.randint(0, height - dy + 1)
    return img[y:(y+dy), x:(x+dx), :]


def crop_generator(batches, crop_length):
    """Take as input a Keras ImageGen (Iterator) and generate random
    crops from the image batches generated by the original iterator.
    """
    while True:
        batch_x, batch_y = next(batches)
        batch_crops = np.zeros((batch_x.shape[0], crop_length, crop_length, 3))
        for i in range(batch_x.shape[0]):
            batch_crops[i] = random_crop(batch_x[i], (crop_length, crop_length))
        yield (batch_crops, batch_y)

def get_base_model(model_name):
    if model_name == "mobilenet":
        base_model = MobileNet(include_top=False, weights='imagenet', input_tensor=None,
                        input_shape=(config["crop_length"], config["crop_length"], 3))
    elif model_name == "inceptionv3":
        base_model = InceptionV3(include_top=False, weights='imagenet', input_tensor=None,
                        input_shape=(config["crop_length"], config["crop_length"], 3))
    return base_model

def generate_batches(config):

    train_data_gen = ImageDataGenerator(preprocessing_function=preprocess_input,
                                        rotation_range=20,
                                        zoom_range=0.2,
                                        channel_shift_range=10,
                                        horizontal_flip=True)

    train_batches = train_data_gen.flow_from_directory(config["train_split_path"],
                                                       target_size=(config["crop_length"], config["crop_length"]),
                                                       interpolation='lanczos:random',
                                                       class_mode='categorical',
                                                       shuffle=True,
                                                       batch_size=config["batch_size"])

    valid_data_gen = ImageDataGenerator(preprocessing_function=preprocess_input)

    valid_batches = valid_data_gen.flow_from_directory(config["valid_split_path"],
                                                       target_size=(config["crop_length"], config["crop_length"]),
                                                       interpolation='lanczos:center',
                                                       class_mode='categorical',
                                                       shuffle=False,
                                                       batch_size=config["batch_size"])

    test_data_gen = ImageDataGenerator(preprocessing_function=preprocess_input)

    test_batches = test_data_gen.flow_from_directory(config["test_split_path"],
                                                     target_size=(config["crop_length"], config["crop_length"]),
                                                     interpolation='lanczos:center',
                                                     class_mode='categorical',
                                                     shuffle=False,
                                                     batch_size=config["batch_size"])

    # train_crops = crop_generator(train_batches, config["crop_length"])
    # valid_crops = crop_generator(valid_batches, config["crop_length"])
    # test_crops = crop_generator(test_batches, config["crop_length"])

    # return train_crops, valid_crops, test_crops, train_batches, valid_batches, test_batches
    return train_batches, valid_batches, test_batches

def train(config):

    # generate batches based on image augmentation
    train_batches, valid_batches, test_batches = generate_batches(config)

    # retrieve pre-trained ImageNet model, based on the config
    base_model = get_base_model(config["image_model"])

    # freeze all layers for the base model
    for layer in base_model.layers:
        layer.trainable = False
    # set the last 30 layers as trainable
    for layer in base_model.layers[30:]:
        layer.trainable = True

    x = base_model.output
    x = tensorflow.keras.layers.Flatten()(x)
    x = tensorflow.keras.layers.Dropout(0.5)(x)
    output_layer = tensorflow.keras.layers.Dense(config["number_of_classes"], activation='softmax', name='softmax')(x)
    fined_tuned_model = tensorflow.keras.Model(inputs=base_model.input, outputs=output_layer)

    fined_tuned_model.compile(optimizer=tensorflow.keras.optimizers.Adam(lr=1e-5),
                      loss='categorical_crossentropy', metrics=['accuracy'])

    print(config)
    # train the model
    fined_tuned_model.fit_generator(train_batches,
                            steps_per_epoch=train_batches.samples // config["batch_size"],
                            validation_data=valid_batches,
                            validation_steps=valid_batches.samples // config["batch_size"],
                            epochs=config["epochs"], use_multiprocessing=False)

    valid_scores = fined_tuned_model.evaluate_generator(valid_batches, steps=valid_batches.samples // config["batch_size"], use_multiprocessing=False)
    test_scores = fined_tuned_model.evaluate_generator(test_batches, steps=test_batches.samples // config["batch_size"], use_multiprocessing=False)
    print("Valid Loss: " + str(valid_scores[0]))
    print("Valid Accuracy: " + str(valid_scores[1]))
    print("Test Loss: "+str(test_scores[0]))
    print("Test Accuracy: " + str(test_scores[1]))

    # save trained weights
    fined_tuned_model.save(config["output_file_path"])

    # # check if results folder exists
    # if not file_utils.path_exists("image_model_results"):
    #     file_utils.create_folder("image_model_results")
    #
    # # save model test accuracy to a file
    # model_results = {}
    # if file_utils.path_exists("image_model_results/model_results.txt"):
    #     content = file_utils.read_file_to_set("image_model_results/model_results.txt")
    #     for c in content:
    #         t = c.split("\t")
    #         model_results[t[0]] = float(t[1])
    # # add the current model
    # model_results[config["output_file_path"]] = float(test_scores[1])
    #
    # # sort and save
    # sorted_model_results = sorted(model_results, reverse=True, key=model_results.get)
    # model_results_output = ""
    # for model_name in sorted_model_results:
    #     model_results_output += model_name + "\t" + str(model_results[model_name]) + "\n"
    #
    # # save the content
    # file_utils.save_string_to_file(model_results_output, "image_model_results/model_results.txt")


if __name__ == "__main__":
    argv = (sys.argv[1:])
    config_path = 'image_model_config.json'
    try:
        opts, args = getopt.getopt(argv, "hc:o:")
    except getopt.GetoptError:
        print('train_image_model.py -c <config_path>')
        sys.exit(2)
    for opt, arg in opts:
        if opt == '-h':
            print('train_image_model.py -c <config_path>')
            sys.exit()
        elif opt  == "-c":
            config_path = arg

    if config_path != '':
        with open(config_path) as json_file:
            config = json.load(json_file)
            train(config)
    else:
        print('train_image_model.py -c <config_path>')